% 
%jff-notes
%
\documentclass[11pt]{article}
\usepackage[pdftex]{graphicx}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{relsize}
\usepackage{textcomp}
%processed for 10 pt 
%\documentstyle[epsf,psfig]{article}
%\documentstyle[epsf]{article}
\oddsidemargin 0pt
\topmargin -0.0cm
\textwidth 6.2in
\textheight 8.5in
\baselineskip 18pt
%\renewcommand{\baselinestretch} {1.5}
\newenvironment{nitemize}
   {\begin{list}{\begin{math}\bullet\end{math}}%
      {\setlength{\leftmargin}{5mm}
       \setlength{\topsep}{1mm}
       \setlength{\parsep}{0in}
       \setlength{\itemsep}{.7mm}}}%
   {\end{list}}

\newcommand{\fract}[2]{\frac{\textstyle #1}{\textstyle #2}}
\newcommand{\trans}[3]{#1 \stackrel{#2}{\longrightarrow} #3}
\newcommand{\notrans}[3]{#1 \stackrel{#2}{\not\! \longrightarrow} #3}
\bibliographystyle{plain}
\begin{document}
\title{Qt-DAB: structure of the software}
\ \\
{\small {\em an informal introduction}}
}
\author{
Jan van Katwijk\\
Lazy Chair Computing \\
The Netherlands\\
{\em J.vanKatwijk@gmail.com}\\
\ \\
}
%\date{}
\maketitle
%\baselineskip 22pt
\section{Introduction}
Qt-DAB is written in C++ and makes use of the Qt toolset.
The program implements a series of transformations on an input
that consists of a continuous stream of I/Q samples, with an
inputrate of 2048000.
The implementation of the processing can be thought of to
exist of 4 stages:
\begin{enumerate}
\item reading samples
\item mapping samples onto DAB frames 
\item extracting services from these DAB frames
\item generating output
\end{enumerate}

The main "driver" of the implementation is in a class "dabProcessor",
a class implementing an interface to the input device is one
of its parameters, as are the dabMode, some settings and a number
of buffers, with which data is passed to the GUI handler.

The dabProcessor extracts the samples from the input device (through
a class "sampleReader", does time synchronization to estimate the
first sample of the non-null part of a DAB frame (using a class
"timeSyncer"), does the fine time synchronization - determining the
first sample of the first data block (using a class "phaseReference"),
collects the samples for the data blocks of the DAB frame, and
makes a guess of the small error correction.

Decoding the first few data blocks, FIC blocks, is delegated to an instance
of the class "ofdmDecoder", processing the result is delegated
to an instance of the class ficHandler.

Decoding of the remaining data blocks, MSC blocks, is delegated to
an instance of the class "mscProcessor". On selecting a service,
a delegate is instatiated that is capable of dealing with it.
Audio output is send back to the GUI for processing by an output module.

The rationale for this choice is that the dabProcessor proper and
the mscProcessor can be executed in different threads.

Control of the GUI is implemented in the class "RadioInterface",
it implements the two way communication betwene the (visual) outside
world and the processing chain.

\section{The dabProcessor and processing}
\subsection{the dabProcessor}
The dabProcessor is built as a thread, pulling the data in,
processing the samples and emitting dabBlocks to its delegates.
The "run" function will call upon an instance of the
class "sampleReader" to obtain the samples - corrected for any
frequency offset that might occur.

If there is no (coarse) time sychronization yet, an instance
of the class "timeSyncer" will try to obtain this.
If the timeSyncer is successfull, a reasonable indication of
where the OFDM frame starts is given.
We keep on looping until such an indication is found.

If such an indication is found, a - pretty arbitary - amount
of samples are read in, and passed on to a an instance of the
class "phaseReference". The latter will compute the precise offset
of where the data is to be found in the sample stream.

Reading in a frame is then straight forward, the first data block
is used for frequency synchronization and acts as a reference for decoding
the next block, samples constituing the next blocks are read in
and the blocks are collected.

The first datablocks are passed on to an instance of the class ficHandler,
that class builds a structure with a description of the data that is
contained in the MSC blocks.

The remaining data blocks are passed on to the instance of the mscHandler.

While reading in the data blocks, an estimate is made of the small (fine)
frequency offset, by averaging over all blocks of the frame.

Note that when there is time synchronization, there is not need to
repeat that part of the procedure for the next DAB frame, so the code
ends with a jump back to the part fine syncing with the next DAB frame.

\subsection{The class "phaseReference"}

A class "phaseReference" is built to handle the identification of the
first sample of the first datablock in a DAB frame and the computation
of the coarse frequency offset.

Identification of the first sample is possible since the pattern of
the first data block as transformed into the frequency domain is predefined.

The actual computation is done by taking the IFFT of the product of the
FFT of the incoming data and the aforementioned pattern.

The frequency offset is computed by correlating elements of the
predefined pattern with the FFT of the first data block.

\subsection{The class "ofdmDecoder"}

The mapping of the first data block and the first few FIC blocks
is done in the class ofdmDecoder. Decoding is by computing - for each
relevant carrier - the product of the carrier with the value of the
carrier in the preceding block. Since there is some interleaving
involved, computation takes the interleaving into account.

\subsection{The classed "ficHandler" and "fibProcessor"}

The decoder data of the FIC blocks is passed on to the instance of the
ficHandler class. The class itself is derived from the fibProcessor class,
that one does the real interpretation.

The incoming data is partitioned into segments of 2304 (soft) bits,
these segments are depunctured according to a predefined rule, and
are fed into a deconvolutional decoder.

The result are segments of 768 (hard) bits, each consisting of three
vectors of 256 bits, 240 data bits and a 16 bit CRC.

These vectors - if the CRC check is passed - are further processed
by (an instance of) the "fibProcessor" class.

The latter maintains three 64 element vectors, one for the "subChannels",
one for the "subServices" and one for the "services".

\section{The mscHandler}

The class mscHandler is built as a thread, buffering the input.
The "run" function will read the raw datablocks and will decode them,
i.e. map them onto (soft)bits. These bits are collected into CIFs.

This approach is chosen to (more or less) balance the workload between
the ofdmProcessor and the mscHandler.

As long as no service is selected, it ends here. If/when a service
is selected, the GUI passes a description of the selected service
to the mscHandler. The mscHandler then -  if applicable - terminates
delegates operating on the previously selected service, and adds
an appropriate delete to a "stack" of delegates. This allows handling
of subservices.

The service description contains an indication of the startaddress
of the data in the CIF, of the length of the data segment, and an
indication whether it is an audio or data (sub)service.

Since the mscHandler has both the dabProcessor and the GUI as client,
some locking is introduced, locking by simple mutexes.

The GUI is the controller here, it will interrogate the FIC and
instruct the mscHandler.

An audio (sub)service will be handled by an instance of the class 
"audioProcessor", a data (sub)service by an instance of the class
"dataProcessor".

Note that a service may have subservices. While not common, it happens
with e.g. Belgian DAB services: a subservice is encoded that contains the
MOT data.
To accomodate this, the mscHandler is capable of dealing with more than one
service (note that from an mscHandler's point of view, the notio of
subservice is meaningless, they just are services.

The mscHandler therefore puts requests for handling services onto a vector,
and handles all elements of this vector when extracting data from
services from the CIF.

4.1 Handling audio.

Whenever an audio service is started, an instance of the class
"audioProcessor" is created. On instantiation, the correct handler
for depuncturing and deconvolution is selected, as well as the
audio handler. i.e. MP2 or AAC.

The instance will get segments of (soft) bits, it will do the
time deinterleaving in line, it will pass on the segments resulting from
the deinterleaving to the uep or eep handler and pass on the result of
depuncturing and deinterleaving to either the MP2 or MP4 processor.

The implementation of the class is - depending on a compile-time setting -
synchronous or asynchronous. In the asynchronous case, the
code of the class is executed in a separate thread, with some
elementary buffering between the mscHandler and the audioProcessor.

4.1.1 depuncturing and deconvolution.

Based on data, stored in the FIB, the processor knows which depuncturing
scheme to apply to the data.

1. in an eep scheme (implemented in a class "eep_protection")
the schemes and the different subsegments on these
 different depuncturing
schemes have to be applied, are determined by predefined tables.

2. in a uep scheme (implemented in a class "uep_protection") the
4 subsegments and the schemes to be applied,
are detemined by an index in a table, where the index is computed
by (a) the bitrate, and (b) the protection level specificied.

To improve efficiency, in both cases a vector is created on instantiation
of the class that contains a "true" value on the positions where the
input is used, a "false" otherwise.

In both cases, the different segments are depunctured by adding "0"
values on the specified places. 

Both classes are implemented as being derived from the class "viterbi_768".

4.1.2 MP2 handling
The "classic" DAB encodes the audio in MP2 format. Handling MP2 is
delegated to a class "mp2Processor". That class is heavily based on the
open source KJMP2 library. The class merely embeds the code of that library
and adds some code to extract PAD data - if any.

Handling DAB segments merely consists of passing on the incoming segments
to the instance of the class mp2Processor.

4.1.3 MP4 handling
Handling DAB+ is slightly more complex. A DAB+ superframe consists of the
concatenation of the selected data segments from 5 consecutive CIFs.

Such a superframe then contains a header, and an index to up to 6
AAC encoded audio segments.

The main handler for superframes is the instance of the mp4Processor.

It will collect - and concatenate - segments from the consecutive CIFs and
it will try to detect the header of a superframe - delegated to a class
direcode-checker -. If such a header is not found, a new segment is added,
the oldest one deleted, and a next check is made on the
existence of a superframe.

If a potential superframe is detected, the data in the segments is
handed over to a function that will first handle the Reed-Solomon
error detection/correction.  The superframe is
split up into RSDims segments of 120 bytes, each of these send to the
Reed-Solomon decoder (implemented in a class "reedSolomom").
The decoder returns -1 is too many errors are detected in the segment,
otherwise it corrects the errors and returns the number
of corrected bytes.

Obviously, if too many errors are detected, there is a real chance that
- in spite of the detection of the header - the current data is not
a valid superframe.

If, on the other hand the errors could be corrected, the assumption
is that the data is a real superframe, and the encoded audio fragments
are extracted. The position and length of each of the encoded
audio fragments is given in a table, to be found at the beginning of
the superframe.

The encoded audio segments (the AU's) are then passed on to a wrapper
around the external faad library to transform the data into PCM samples.

The class "faad-decoder" implements the wrapper. It will put the
resulting PCM samples in a buffer, shared with the GUI, and signal the
GUI that there is some audio data.


4.2 Data Handling.

Service channels may contain - non-audio - data, both as primary
service, and - as mentioned earlier - as subservice.
MOT data is handled, both as primary and subservice.
Other forms of data are only supported when appearing in a primary service.

TPG data - often encrypted - is collected and - if so configured - made
available to clients through an IP address. EPG data is collected and
written to a file. Journaline data is send to an untested handler, and
IP data is send to IP address 8888.

MOT data though - pictures, slideshows, files etc - is handled by the 
DAB software.

Handling of data segments follows a similar pattern as handling audio
data segments. 
An instance of the class "dataBackend" receives the segments, does
the time deinterleaving and depuncturing/deconvolution and
the result is handed over to an instance of the class "dataProcessor".
The latter collects the packets and dispatches on the
type of data to be handled.




